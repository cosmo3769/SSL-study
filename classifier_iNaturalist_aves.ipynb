{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cosmo3769/SSL-study/blob/classifier2/classifier_iNaturalist_aves.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the notebook using colab environment: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the notebook is running on colab or not.\n",
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "except:\n",
    "    COLAB = False\n",
    "print(f'Is the notebook using colab environment: {COLAB}')\n",
    "\n",
    "if COLAB:\n",
    "    # Install W&B for MLOPs.\n",
    "    print(f'Installing Weights and Biases')\n",
    "    !pip install --upgrade wandb\n",
    "\n",
    "# Login to your W&B account.\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgVEwLHslOyn"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(dataset_name: str, dataset_type: str, version: str='latest'):\n",
    "    \"\"\"\n",
    "    Utility function to download the data saved as W&B artifacts and return a dataframe\n",
    "    with path to the dataset and associated label.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): The name of the dataset - `train`, `val`, `out-class`, and `in-class`.\n",
    "        dataset_type (str): The type of the dataset - `labelled-dataset`, `unlabelled-dataset`.\n",
    "        version (str): The version of the dataset to be downloaded. By default it's `latest`,\n",
    "            but you can provide different version as `vX`, where, X can be 0,1,...\n",
    "            \n",
    "        Note that the following combination of dataset_name and dataset_type are valid:\n",
    "            - `train`, `labelled-dataset`\n",
    "            - `val`, `labelled-dataset`\n",
    "            - `in-class`, `unlabelled-dataset`\n",
    "            - `out-class`, `unlabelled-dataset`\n",
    "            \n",
    "    Return:\n",
    "        df_data (pandas.DataFrame): Dataframe with path to images with associated labels if present.\n",
    "    \"\"\"\n",
    "    # Download the dataset.\n",
    "    wandb_api = wandb.Api()\n",
    "    artifact = wandb_api.artifact(f'ayush-thakur/ssl-study-data/{dataset_name}:{version}', type=dataset_type)\n",
    "    artifact_dir = artifact.download()\n",
    "    \n",
    "    # Open the W&B table downloaded as a json file.\n",
    "    json_file = glob.glob(artifact_dir+'/*.json')\n",
    "    assert len(json_file) == 1\n",
    "    with open(json_file[0]) as f:\n",
    "        data = json.loads(f.read())\n",
    "        assert data['_type'] == 'table'\n",
    "        columns = data['columns']\n",
    "        data = data['data']\n",
    "\n",
    "    # Create a dataframe with path and label\n",
    "    df_columns = ['image_path', 'width', 'height']\n",
    "    if 'label' in columns:\n",
    "        df_columns+=['label']\n",
    "    data_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    for idx, example in tqdm(enumerate(data)):\n",
    "        image_dict = example[1]\n",
    "        image_path = os.path.join(train_dir, image_dict.get('path'))\n",
    "        height = image_dict.get('height')\n",
    "        width = image_dict.get('width')\n",
    "        \n",
    "        df_data = [image_path, width, height]\n",
    "        if 'label' in columns:\n",
    "            df_data+=[example[2]]\n",
    "        data_df.loc[idx] = df_data\n",
    "    \n",
    "    # Shuffle the dataframe\n",
    "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact train:latest, 351.17MB. 3960 files... Done. 0:0:0\n",
      "3959it [00:07, 523.00it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact val:latest, 184.02MB. 2001 files... Done. 0:0:0\n",
      "2000it [00:03, 524.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 462 ms, total: 13.3 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = download_dataset('train', 'labelled-dataset')\n",
    "valid_df = download_dataset('val', 'labelled-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./artifacts/train:v0/media/images/e18792a1abc3...</td>\n",
       "      <td>500</td>\n",
       "      <td>446</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./artifacts/train:v0/media/images/c7029a52a870...</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./artifacts/train:v0/media/images/9d7f38451468...</td>\n",
       "      <td>500</td>\n",
       "      <td>357</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./artifacts/train:v0/media/images/590770a32881...</td>\n",
       "      <td>500</td>\n",
       "      <td>425</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./artifacts/train:v0/media/images/c9114d607dc3...</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path width height label\n",
       "0  ./artifacts/train:v0/media/images/e18792a1abc3...   500    446   116\n",
       "1  ./artifacts/train:v0/media/images/c7029a52a870...   500    375    12\n",
       "2  ./artifacts/train:v0/media/images/9d7f38451468...   500    357   127\n",
       "3  ./artifacts/train:v0/media/images/590770a32881...   500    425    96\n",
       "4  ./artifacts/train:v0/media/images/c9114d607dc3...   500    375    16"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAFEoyPLYE5D"
   },
   "source": [
    "## Build an input pipeline with tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TbgDVKZ3gO0O"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, GlobalMaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6RSMxO6vqIV"
   },
   "source": [
    "### Training input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "FeKjf_rItXyD",
    "outputId": "a54a5dff-1495-4a2a-fd50-53342d71f564"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a990b349-b09f-4ebd-8fb5-465f4bd10272\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/train/0/0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/train/0/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/train/0/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/train/0/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/train/0/4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/train/train/199/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/train/train/199/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/train/train/199/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/train/train/199/4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/train/train/199/5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3959 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a990b349-b09f-4ebd-8fb5-465f4bd10272')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a990b349-b09f-4ebd-8fb5-465f4bd10272 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a990b349-b09f-4ebd-8fb5-465f4bd10272');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      category_id                       file_name\n",
       "0               0    /content/train/train/0/0.jpg\n",
       "1               0    /content/train/train/0/1.jpg\n",
       "2               0    /content/train/train/0/2.jpg\n",
       "3               0    /content/train/train/0/3.jpg\n",
       "4               0    /content/train/train/0/4.jpg\n",
       "...           ...                             ...\n",
       "3954          199  /content/train/train/199/1.jpg\n",
       "3955          199  /content/train/train/199/2.jpg\n",
       "3956          199  /content/train/train/199/3.jpg\n",
       "3957          199  /content/train/train/199/4.jpg\n",
       "3958          199  /content/train/train/199/5.jpg\n",
       "\n",
       "[3959 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labelled['file_name'] = training_labelled['file_name'].str.replace(r'trainval_images/', '')\n",
    "training_labelled['file_name'] = '/content/train/train/' + training_labelled['file_name'].str[:]\n",
    "training_dataframe = training_labelled.drop(['image_id', 'id', 'width', 'height'], axis = 1)\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nVzcaG8r7huK"
   },
   "outputs": [],
   "source": [
    "# Coverting DataFrame to list to pass it to tf.data dataloader\n",
    "\n",
    "file_name = training_dataframe['file_name'].to_list()\n",
    "label = training_dataframe['category_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FcK0EZQoxidw"
   },
   "outputs": [],
   "source": [
    "train_slice = tf.data.Dataset.from_tensor_slices((file_name, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqgZmZZ3y9IF",
    "outputId": "7670f9fc-cc43-4651-a94f-8812787fa451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'category': 0\n",
      "'feature': b'/content/train/train/0/0.jpg'\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_slice.take(1):\n",
    "  print(\"'category': {}\".format(label_batch))\n",
    "  print(\"'feature': {}\".format(feature_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TyrXq52E-sCH"
   },
   "outputs": [],
   "source": [
    "# Decode the images and resize the images to the mentioned shape\n",
    "\n",
    "@tf.function\n",
    "def parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "\n",
    "    #Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.io.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "    #This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9B949HBs-wB7"
   },
   "outputs": [],
   "source": [
    "# def train_preprocess(image, label):\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "#     image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
    "#     image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "\n",
    "#     #Make sure the image is still in [0, 1]\n",
    "#     image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "#     return image, label\n",
    "\n",
    "# # Apply training augmentation\n",
    "# train_transforms = Compose([\n",
    "#             Resize(224, 224, p=1),\n",
    "#             Rotate(limit=20),\n",
    "#             Cutout(num_holes=8, max_h_size=30, max_w_size=30, p=1.0),\n",
    "#             HorizontalFlip(p=0.7),\n",
    "#             VerticalFlip(p=0.4),\n",
    "#             Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406],\n",
    "#                 std=[0.229, 0.224, 0.225],\n",
    "#                 max_pixel_value=255.0,\n",
    "#                 p=1.0,\n",
    "#             ),\n",
    "#         ])\n",
    "\n",
    "# # Apply validation augmentation\n",
    "# valid_transforms = Compose([\n",
    "#             Resize(224, 224, p=1),\n",
    "#             Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406],\n",
    "#                 std=[0.229, 0.224, 0.225],\n",
    "#                 max_pixel_value=255.0,\n",
    "#                 p=1.0,\n",
    "#             ),\n",
    "#         ])\n",
    "\n",
    "# def aug_train_fn(image):\n",
    "#     data = {\"image\":image}\n",
    "#     aug_data = train_transforms(**data)\n",
    "#     aug_img = aug_data[\"image\"]\n",
    "\n",
    "#     return aug_img.astype(np.float32) \n",
    "\n",
    "# def aug_valid_fn(image):\n",
    "#     data = {\"image\":image}\n",
    "#     aug_data = valid_transforms(**data)\n",
    "#     aug_img = aug_data[\"image\"]\n",
    "\n",
    "#     return aug_img.astype(np.float32) \n",
    "\n",
    "# def train_augmentations(image, label):\n",
    "    \n",
    "#     aug_img = tf.numpy_function(func=aug_train_fn, inp=[image], Tout=tf.float32)\n",
    "#     aug_img.set_shape((224, 224, 3))\n",
    "\n",
    "#     return aug_img, label\n",
    "\n",
    "# def valid_augmentations(image, label):\n",
    "\n",
    "#     aug_img = tf.numpy_function(func=aug_valid_fn, inp=[image], Tout=tf.float32)\n",
    "#     aug_img.set_shape((224, 224, 3))\n",
    "\n",
    "#     return aug_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ndZj7iWI-3B-"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "training_dataset = train_slice.shuffle(len(file_name))\n",
    "training_dataset = training_dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "# training_dataset = training_dataset.map(train_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "training_dataset = training_dataset.batch(32)\n",
    "training_dataset = training_dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fINlK91ViZ0Q",
    "outputId": "b0ca1286-6822-4527-a18d-e367955c6b71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       "array([110,  59,  96,  81,  91,  45, 167,  79, 140,  58, 102,  63,  54,\n",
       "        13,  32,  83,  73,  86,  74,  26,  50,  54,  16, 111, 159, 191,\n",
       "        14,   2,  37,  67,   5,  13], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(iter(training_dataset))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bBszbMGwiSW"
   },
   "source": [
    "### Validation input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "w2hatEGFz_LP",
    "outputId": "6e1d91cc-5c94-4230-d4bf-c76b619d0671"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-09c8f843-aa70-4d79-a704-71c75c2216de\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/val/val/0/30.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/val/val/0/31.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/val/val/0/32.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/val/val/0/33.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>/content/val/val/0/34.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/val/val/199/11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/val/val/199/12.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/val/val/199/13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/val/val/199/14.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>199</td>\n",
       "      <td>/content/val/val/199/15.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c8f843-aa70-4d79-a704-71c75c2216de')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-09c8f843-aa70-4d79-a704-71c75c2216de button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-09c8f843-aa70-4d79-a704-71c75c2216de');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      category_id                    file_name\n",
       "0               0    /content/val/val/0/30.jpg\n",
       "1               0    /content/val/val/0/31.jpg\n",
       "2               0    /content/val/val/0/32.jpg\n",
       "3               0    /content/val/val/0/33.jpg\n",
       "4               0    /content/val/val/0/34.jpg\n",
       "...           ...                          ...\n",
       "1995          199  /content/val/val/199/11.jpg\n",
       "1996          199  /content/val/val/199/12.jpg\n",
       "1997          199  /content/val/val/199/13.jpg\n",
       "1998          199  /content/val/val/199/14.jpg\n",
       "1999          199  /content/val/val/199/15.jpg\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labelled['file_name'] = validation_labelled['file_name'].str.replace(r'trainval_images/', '')\n",
    "validation_labelled['file_name'] = '/content/val/val/' + validation_labelled['file_name'].str[:]\n",
    "validation_dataframe = validation_labelled.drop(['image_id', 'id', 'width', 'height'], axis = 1)\n",
    "validation_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5zNV7MnEJ8ph"
   },
   "outputs": [],
   "source": [
    "# Coverting DataFrame to list to pass it to tf.data dataloader\n",
    "\n",
    "val_file_name = validation_dataframe['file_name'].to_list()\n",
    "val_label = validation_dataframe['category_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cJWbMRUeKIiQ"
   },
   "outputs": [],
   "source": [
    "val_slices = tf.data.Dataset.from_tensor_slices((val_file_name, val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNErftYPKQCd",
    "outputId": "0e073835-0895-438c-e164-37fedfb641ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'category': 0\n",
      "'feature': b'/content/val/val/0/30.jpg'\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in val_slices.take(1):\n",
    "  print(\"'category': {}\".format(label_batch))\n",
    "  print(\"'feature': {}\".format(feature_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "UTr2gFksKYr3"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# validation_dataset = val_slices.shuffle(len(val_file_name))\n",
    "validation_dataset = val_slices.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "# validation_dataset = validation_dataset.map(train_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(32)\n",
    "validation_dataset = validation_dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLYfb4V7L656",
    "outputId": "953e57bd-acb3-46c6-9a2f-92e82044bb1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       "array([143,  43, 134,  97,   4,  15,  34,  31,  85, 124,  58,   7,  33,\n",
       "        59, 181,   5,  11,  86, 134,  80,  65, 136, 145, 106,  23,  56,\n",
       "       187,  92, 147,  26,  28, 163], dtype=int32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(iter(training_dataset))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoDf6z8qYLes"
   },
   "source": [
    "## Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gvpp4Dwl1Vsd",
    "outputId": "10c45bce-970a-40b7-9216-4a3cf954aed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Glo  (None, 512)              0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,817,288\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "  \n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                             base_model,\n",
    "                             tf.keras.layers.GlobalMaxPooling2D(),\n",
    "                             tf.keras.layers.Dense(200, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APC76lOgYdwM"
   },
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "hz4VstFt_1oi"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rURxLUumCn4"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "        training_dataset,\n",
    "        epochs = 20,\n",
    "        validation_data = validation_dataset,\n",
    "        callbacks=[\n",
    "          # Stopping our training if val_accuracy doesn't improve after 20 epochs\n",
    "          tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29JcCD2ySXkM"
   },
   "source": [
    "## Visualization of model's prerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3iz4BdISbXh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# store results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "  \n",
    "  \n",
    "# plot results\n",
    "# accuracy\n",
    "plt.figure(figsize=(10, 16))\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# loss\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pdo5F93XYrCH"
   },
   "source": [
    "## Evaluation on Validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTzQyjp-SnXG"
   },
   "outputs": [],
   "source": [
    "accuracy_score = model.evaluate(validation_dataset)\n",
    "print(accuracy_score)\n",
    "print(\"Accuracy: {:.4f}%\".format(accuracy_score[1] * 100)) \n",
    "  \n",
    "print(\"Loss: \",accuracy_score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36H4NX55Ys-p"
   },
   "source": [
    "## Prediction on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yYNfCagSrBV"
   },
   "outputs": [],
   "source": [
    "images_annotations_test['file_name'] = '/content/test/' + images_annotations_test['file_name'].str[:]\n",
    "testing_dataframe = images_annotations_test.drop(['width', 'height', 'id'], axis = 1)\n",
    "testing_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vAsZLWpSyhD"
   },
   "outputs": [],
   "source": [
    "file_name = testing_dataframe['file_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfRzU3jnS0qB"
   },
   "outputs": [],
   "source": [
    "test_slice = tf.data.Dataset.from_tensor_slices(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-FmL3v9S2sN"
   },
   "outputs": [],
   "source": [
    "for feature_batch in test_slice.take(1):\n",
    "  print(\"'feature': {}\".format(feature_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEfpTWlbS4sP"
   },
   "outputs": [],
   "source": [
    "# Decode the images and resize the images to the mentioned shape\n",
    "\n",
    "@tf.function\n",
    "def test_parse_function(filename):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "\n",
    "    #Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.io.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "    #This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRfjsYfoS6-X"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "test_dataset = test_slice.map(test_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32)\n",
    "test_dataset = test_dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdWJfftwS9jN"
   },
   "outputs": [],
   "source": [
    "inputs = next(iter(training_dataset))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hn1bFfevS_aM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPJRkTGZqmWo7QGJMY5kuAs",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "classifier_iNaturalist_aves.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
